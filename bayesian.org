* docker stuff
** start container
#+BEGIN_SRC emacs-lisp :results none
(docker/start-sbcl-with-sly "bayesian-analysis" "deepestthought42/sbcl-1.3.15-bayesian-analysis:20170522"
                            '(("/home/renee/phd/src/penning-analysis.project/" "/src/")
                              ("/home/renee/phd/data_analysis/201607CD_In/" "/data_analysis/")
                              ("/home/renee/phd/data_analysis/fitting_cross_check/" "/fitting_cross_check/")
                              ("/home/renee/phd/data_analysis/2016_version_of_intrap/midas-files/" "/intrap/"))
                            4005 "/src/")
#+END_SRC
** version history
| date                   | comment                            |
|------------------------+------------------------------------|
| [2017-05-02 Tue 22:05] | installed nlopt                    |
| [2017-05-17 Wed 12:07] | installed libblas, lapack          |
| [2017-05-18 Thu 11:30] | symbols seem to have been mixed up |
| [2017-05-22 Mon 17:43] | changed distro to elementary       |


** prepare session
#+BEGIN_SRC lisp :results none
(ql:quickload :fare-quasiquote)
(ql:quickload :bayesian-analysis)
(ql:quickload :penning-analysis)
#+END_SRC


   
* TODOs
** DONE introduce code to block writing slots
min, max, prior, etc should be immutable
** DONE method for plotting data
** DONE look at metropolis hastings and the signs 
** DONE make binning issues more sane
- might be best to actually give a number of bins and then determine
  the bin width by: (max - min)/no-bins
  - how does that work for scale parameters though ?
** DONE make konig work
** DONE work on likelihood code
the current way of doing it seems overly complicated, let's not use a
macro and create functions instead
** TODO 2d model with nlopt
let's see how 2d fitting works with nlopt
*** code
**** first tests
#+BEGIN_SRC lisp 
(in-package #:penning-analysis)

(defparameter *test-file*
  (midas:read-mpet-midas-file
   "/home/renee/phd/data_analysis/201607CD_In/midas-files/20160630/run277347.mid"))


(defparameter *data*
  (tof-data:data *test-file* 1
		 :min-tof 20d0
		 :max-tof 50d0
		 :min-no-ions 1
		 :max-no-ions 1))

(let ((params (fp:get-init-params-from-midas-file 
	       ,*test-file* 25d0
               :om-c-deviation 4d0
	       :rho-m0-sampler '(ba:gaussian-sampler :sigma 1d-5)
	       :om-c-sampler '(ba:gaussian-sampler :sigma 1d0)
	       :tof-offset-min 0.1d0 :tof-offset-max 1d0 :tof-offset 0.5d0
	       :contaminant-offset-max 40d0
	       :rho-m0 3d-4
	       :rho-m0-min 2d-4
	       :rho-m0-max 5d-4)))
  (defparameter *res-nlopt-2d*
    (ba:find-optimum
     (make-instance 'ba:nlopt :max-time 5d0)
     (apply #'make-instance 'fp:2d-bayes-konig params)
     (ba:initialize-from-source 'fp:2d-tof-distribution *data*))))




(defparameter *param-results* (ba:get-parameter-results  *res-nlopt-2d* :no-bins 20))

(labels ((cmd (fmt-str &rest args)
	   (mgl-gnuplot:command (apply #'format nil fmt-str args))))
  (mgl-gnuplot:with-session ()
    (cmd "reset")
    (cmd "set terminal wxt enhanced font 'Georgia,8' dashed")
    (let+ (((&slots ba::input-model ba:model ba:data) *res-nlopt-2d*))
      (mgl-gnuplot:plot*
       (ba:plot-result *param-results*))) 
    (cmd "unset output")))


(labels ((cmd (fmt-str &rest args)
	   (mgl-gnuplot:command (apply #'format nil fmt-str args))))
  (mgl-gnuplot:with-session ()
    (cmd "reset")
    (cmd "set terminal wxt enhanced font 'Georgia,8' dashed")
    (let+ (((&slots ba::input-model ba:model ba:data) *res-nlopt-2d*))
      (mgl-gnuplot:plot*
       (ba:plot-parameter-distribution *param-results* 'fp::p-interest))) 
    (cmd "unset output")))
#+END_SRC
**** intrap file
#+BEGIN_SRC lisp
(in-package #:penning-analysis)

(defparameter *in-file* (midas:read-mpet-midas-file "/intrap/20140914/run221831.mid"))


(defparameter *data-intrap*
  (tof-data:data *in-file* 1
		 :min-tof 10d0
		 :max-tof 22d0
		 :min-no-ions 1
		 :max-no-ions 2))


(let ((params (fp:get-init-params-from-midas-file
	       ,*in-file* :om-c-deviation 30d0
	       :rho-m0-sampler '(ba:gaussian-sampler :sigma 1d-5)
	       :om-c-sampler '(ba:gaussian-sampler :sigma 1d0)
	       :tof-offset-min 0.1d0 :tof-offset-max 1d0 :tof-offset 0.5d0
	       :p-interest-min 0.01d0
	       :p-interest-max 1d0
	       :p-interest 0.02d0
	       :contaminant-offset-max 40d0
	       :rho-m0 3d-4
	       :rho-m0-min 3d-4
	       :rho-m0-max 1d-3)))
  (defparameter *res-2d-intrap*
    (ba:find-optimum
     (make-instance 'ba:nlopt :max-time 15d0)
     (apply #'make-instance 'fp:2d-bayes-konig params)
     (ba:initialize-from-source 'fp:2d-tof-distribution *data-intrap*))))



(labels ((cmd (fmt-str &rest args)
	   (mgl-gnuplot:command (apply #'format nil fmt-str args))))
  (mgl-gnuplot:with-session ()
    (cmd "reset")
    (cmd "set terminal wxt enhanced font 'Georgia,8' dashed")
    (mgl-gnuplot:plot*
     (list
      (mgl-gnuplot:data*
       (let+ (((&slots ba:input-model ba:model ba:data) *res-2d-intrap*))
	 (ba:plot-result-models ba:input-model ba:model ba:data :include-input-model nil))
       "with lines"))) 
    (cmd "unset output")))


#+END_SRC

#+RESULTS:
: unset output

*** logbook
- o.k., it finds the minimum but I can't plot the distributions
- maybe because of the cache ?
- no, likely because the log is to small
- so, maybe normalize in the log scale
- now getting division-by-zero when calculating likelihood
- maybe use same trick as for sumlogexp
- formula is:
  \begin{equation}
  \label{eq:4}
  \frac{1}{\sqrt{2\pi}\sigma}
  \left(
        \exp \left[-\frac{\left( T - \mu \left( \omega_{RF} \right)\right)^2}{2\sigma^2} \right]
  + \exp \left[ -\frac{ \left( T - T_{cont}\right)^2}{2\sigma^2} \right]
  \right)
  \end{equation}
- why does this go to zero anyway ?
- ok, ignore datapoints that would give a likelihood of zero, then it works
- now, let's try some of the in-trap data
- so, that works, but I have to limit the tof range quite
  dramatically, since there is pretty big tail on the peaks
- so, maybe introduce a asymmetrical gaussian ?
- yeah, let's do that
- o.k., looking at the 2d konig I have been using, there are quite some errors in it,
- let's fix that first
- ok, this seems to make more sense, but let's test it before judging
- it still fits appropriately, but let's seperate the too distribution
  width, as the background seems to be much broader
- mmh, that didn't work too well, am I actually using the skew ? *->*
  yes, I am, but not the contaminant-sigma
- when using the contaminant-sigma, the optimization is running out of
  time
- I think at least, since I do not know the nlopt result values by
  heart, let's change what we store in the result to the symbols
  instead
- yeah, running out of time
- so, how much time would it need *->* setting limit to 15s and trying
- oh, ok, 5.37s let's look at the output -- writing a small function
  to output model to org-table
- for that, clone org-integration into penning-trap project
- done, also finished function to return org-mode table
- not working, no real table, do it after the break
- testing it with the following:
  #+BEGIN_SRC lisp :results output raw
  (in-package #:penning-analysis)

  (let+ ((model (ba:model *res-2d-intrap*))
         ((&slots ba:all-model-parameters
                  ba:model-parameters-to-marginalize) model))
    (org-mode-integration:output-slots model
                                       (list ba:model-parameters-to-marginalize
                                             (set-difference ba:all-model-parameters
                                                             ba:model-parameters-to-marginalize))
                                       :slot-value-format "~f"))
  #+END_SRC

  #+RESULTS:
  |--------------------+-----------------------|
  | OM-C               |    130961670.86165124 |
  | RHO-M0             | 0.0003000108917287551 |
  | ALPHA              |    0.9999308259956416 |
  | TOF-OFFSET         |    0.3702480012236808 |
  | SIGMA              |    1.3473790781085464 |
  | SIGMA-CONTAMINANT  |    3.5483153004972507 |
  | P-INTEREST         |   0.31396479322945614 |
  | CONTAMINANT-OFFSET |    18.110909561877484 |
  |--------------------+-----------------------|
  | Z-END              |                 1.149 |
  | Z-START            |                   0.0 |
  | DELTA-PHI          |                   0.0 |
  | DAMPING            |                   0.0 |
  | RHO-P0             |             0.0000001 |
  | NO-CONV            |                   1.0 |
  | T-RF               |                  0.02 |
  | V-0                |    0.2836629599463937 |
  | E-0                |                   1.0 |
  | B-MAX              |                   3.7 |
  | OM-RF              |    130962485.95913957 |
  | OM-M               |     38573.73123783692 |
  | Q                  |                  11.0 |
  |--------------------+-----------------------|
- o.k, it fits alpha to be basically one, which would make it
  superflous
- let's remove it and replace it with a gaussian to see what happens
- well, it is a lot slower than what I had before for some reason
- let's not get hung up on performance for now, but look at the values
  #+BEGIN_SRC lisp :results output raw
  (in-package #:penning-analysis)

  (let+ ((model (ba:model *res-2d-intrap*))
         ((&slots ba:all-model-parameters
                  ba:model-parameters-to-marginalize) model))
    (org-mode-integration:output-slots model
                                       (list ba:model-parameters-to-marginalize
                                             (set-difference ba:all-model-parameters
                                                             ba:model-parameters-to-marginalize))
                                       :slot-value-format "~f"))
  #+END_SRC

  #+RESULTS:
  |--------------------+------------------------|
  | OM-C               |      130961670.6118449 |
  | RHO-M0             | 0.00030002348100134223 |
  | TOF-OFFSET         |     0.5327740057967829 |
  | SIGMA              |      1.468445725050243 |
  | SIGMA-CONTAMINANT  |     3.1767201946065273 |
  | P-INTEREST         |    0.42172914305335285 |
  | CONTAMINANT-OFFSET |     20.361997008836813 |
  |--------------------+------------------------|
  | Z-END              |                  1.149 |
  | Z-START            |                    0.0 |
  | DELTA-PHI          |                    0.0 |
  | DAMPING            |                    0.0 |
  | RHO-P0             |              0.0000001 |
  | NO-CONV            |                    1.0 |
  | T-RF               |                   0.02 |
  | V-0                |     0.2836629599463937 |
  | E-0                |                    1.0 |
  | B-MAX              |                    3.7 |
  | OM-RF              |     130962485.95913957 |
  | OM-M               |      38573.73123783692 |
  | Q                  |                   11.0 |
  |--------------------+------------------------|
- is there a difference in performance of the fit (not how long it
  takes) when using two different sigmas ?
- not using two sigmas
    #+BEGIN_SRC lisp :results output raw
  (in-package #:penning-analysis)

  (let+ ((model (ba:model *res-2d-intrap*))
         ((&slots ba:all-model-parameters
                  ba:model-parameters-to-marginalize) model))
    (org-mode-integration:output-slots model
                                       (list ba:model-parameters-to-marginalize
                                             (set-difference ba:all-model-parameters
                                                             ba:model-parameters-to-marginalize))
                                       :slot-value-format "~f"))
  #+END_SRC

  #+RESULTS:
  |--------------------+------------------------|
  | OM-C               |     130961670.56097616 |
  | RHO-M0             | 0.00030170065806623287 |
  | TOF-OFFSET         |     0.9635835898867411 |
  | SIGMA              |     2.7650410715412903 |
  | P-INTEREST         |    0.07539610131072237 |
  | CONTAMINANT-OFFSET |     19.614364357359044 |
  |--------------------+------------------------|
  | Z-END              |                  1.149 |
  | Z-START            |                    0.0 |
  | DELTA-PHI          |                    0.0 |
  | DAMPING            |                    0.0 |
  | RHO-P0             |              0.0000001 |
  | NO-CONV            |                    1.0 |
  | T-RF               |                   0.02 |
  | V-0                |     0.2836629599463937 |
  | E-0                |                    1.0 |
  | B-MAX              |                    3.7 |
  | OM-RF              |     130962485.95913957 |
  | OM-M               |      38573.73123783692 |
  | Q                  |                   11.0 |
  |--------------------+------------------------|
- well, a lot faster and 0.3 Hz different in sigma
- how big is the difference to a run where I cut out most of the tail ?
  Setting :max-tof = 22
- ok, *NA:* looking at performance, specifically start profiling
  distribution generating stuff
- profiling, let's start by looking at the hessian
  #+BEGIN_SRC lisp :results none
  (in-package #:penning-analysis)

  (defparameter *in-file* (midas:read-mpet-midas-file "/intrap/20140914/run221831.mid"))

  (defparameter *data-intrap-performance*
    (tof-data:data *in-file*
                   1
                   :min-tof 10d0
                   :max-tof 22d0
                   :min-no-ions 1
                   :max-no-ions 2))

  (let ((params (fp:get-init-params-from-midas-file
                 ,*in-file* :om-c-deviation 30d0
                 :rho-m0-sampler '(ba:gaussian-sampler :sigma 1d-5)
                 :om-c-sampler '(ba:gaussian-sampler :sigma 1d0)
                 :tof-offset-min -5d0 :tof-offset-max 5d0 :tof-offset 0.5d0
                 :p-interest-min 0.01d0
                 :p-interest-max 1d0
                 :p-interest 0.02d0
                 :contaminant-offset-max 40d0
                 :rho-m0 3d-4
                 :rho-m0-min 3d-4
                 :rho-m0-max 1d-3)))
    (defparameter *res-2d-intrap-performance*
      (ba:find-optimum
       (make-instance 'ba:nlopt :max-time 15d0)
       (apply #'make-instance 'fp:2d-bayes-konig params)
       (ba:initialize-from-source 'fp:2d-tof-distribution *data-intrap-performance*))))





  (labels ((cmd (fmt-str &rest args)
             (mgl-gnuplot:command (apply #'format nil fmt-str args))))
    (mgl-gnuplot:with-session ()
      (cmd "reset")
      (cmd "set terminal wxt enhanced font 'Georgia,8' dashed")
      (mgl-gnuplot:plot*
       (list
        (mgl-gnuplot:data*
         (let+ (((&slots ba:input-model ba:model ba:data) *res-2d-intrap-performance*))
           (ba:plot-result-models ba:input-model ba:model ba:data :include-input-model nil))
         "with lines"))) 
      (cmd "unset output")))


  (sb-profile:profile ba:get-parameter-results ba::get-variance-for-param ba::hessian ba::%do-f-max
                      make-array fp::2d-bayes-konig-model-function)

  (ba:get-parameter-results *res-2d-intrap-performance* :no-bins 20)


  (sb-profile:report)
  #+END_SRC
- starting to profile here
- so, from the above it turns out that we spent most of the time
  calculating the hessian: 
| seconds |    gc | consed        | calls | sec/call | name                                      |
|---------+-------+---------------+-------+----------+-------------------------------------------|
|  11.304 | 0.096 | 4,138,956,976 |   130 | 0.086953 | BAYESIAN-ANALYSIS::HESSIAN                |
|   0.240 | 0.000 | 67,423,520    |     1 | 0.239891 | BAYESIAN-ANALYSIS:GET-PARAMETER-RESULTS   |
|   0.228 | 0.012 | 64,938,224    |   124 | 0.001838 | BAYESIAN-ANALYSIS::%DO-F-MAX              |
|   0.000 | 0.000 | 163,792       |     6 | 0.000000 | BAYESIAN-ANALYSIS::GET-VARIANCE-FOR-PARAM |
|---------+-------+---------------+-------+----------+-------------------------------------------|
|  11.772 | 0.108 | 4,271,482,512 |   261 |          | Total                                     |
- and the hessian also conses an immense amount ...
- what is going on here ?
- let's start by adding declaration and then see if we can remove all
  this consing,
- so with that, it takes 50% longer for some reason, what the hell is
  going on here ?
- how much time does it spend in make-array ? *A:* basically none
- actually, let's create it's own point here

** TODO 2d model profiling
*** code
#+BEGIN_SRC lisp :results none
(in-package #:penning-analysis)


(defun join-property-lists (default additions)
  (iter
  (for add initially additions then (cddr add))
  (until (not add))
  (setf (getf default (first add)) (second add))
  (finally (return default))))


(defun f/make-model (&key (filename "/intrap/20140914/run221831.mid")
			   model-keywords)
  (let+ ((file (midas:read-mpet-midas-file filename))
	 (params (apply #'fp:get-init-params-from-midas-file
			file
			(join-property-lists '(:om-c-deviation 30d0
					       :rho-m0-sampler (ba:gaussian-sampler :sigma 1d-5)
					       :om-c-sampler (ba:gaussian-sampler :sigma 1d0)
					       :tof-offset-min -5d0 :tof-offset-max 5d0 :tof-offset 0.5d0
					       :p-interest-min 0.01d0
					       :p-interest-max 1d0
					       :p-interest 0.02d0
					       :contaminant-offset-max 40d0
					       :rho-m0 3d-4
					       :rho-m0-min 3d-4
					       :rho-m0-max 1d-3)
					     model-keywords))))
    (values (apply #'make-instance 'fp:2d-bayes-konig params) file)))

(defun f/performance-do-fit (&key (filename "/intrap/20140914/run221831.mid")
				  data-keywords model-keywords algorithm-keywords)
  (let+ (((&values model file) (f/make-model :filename filename
					     :model-keywords model-keywords))
	 (data (apply #'tof-data:data file 1 (join-property-lists
					      '(:min-tof 10d0 :max-tof 22d0
						:min-no-ions 1 :max-no-ions 2)
					      data-keywords)))
	 (algorithm (apply #'make-instance 'ba:nlopt
			   (join-property-lists '(:max-time 15d0)
					       algorithm-keywords))))
    (ba:find-optimum algorithm
		     model
		     (ba:initialize-from-source 'fp:2d-tof-distribution data))))

#+END_SRC
*** logbook
- let's start with easier repeatability, then continue with looking at
  nl-opt:optimization in terms of usage
- with that, examine what happens if we change stuff
- so, let's get a baseline on where we are:
  #+BEGIN_SRC lisp 
  (in-package #:penning-analysis)

  (f/performance-do-fit)
  (sb-profile::unprofile-all)
  (sb-profile:reset)
  (sb-profile:profile ba:get-parameter-results ba::get-variance-for-param
                      ba::hessian
                      ba::%do-f-max
                      make-array
                      ;fp::2d-bayes-konig-model-function
                      )

  (time
   (ba:get-parameter-results *res-2d-intrap-performance* :no-bins 20))

  #+END_SRC

  #+RESULTS:
  : #<BAYESIAN-ANALYSIS::OPTIMIZED-PARAMETERS {1010345333}>
- with the following result:
  | seconds |    gc | consed        |      calls | sec/call | name                                       |
  |---------+-------+---------------+------------+----------+--------------------------------------------|
  |  13.569 | 0.040 | 1,833,178,976 |        130 | 0.104376 | BAYESIAN-ANALYSIS::HESSIAN                 |
  |   6.997 | 0.048 | 2,369,177,696 | 50,061,312 | 0.000000 | FIT-PENNING::2D-BAYES-KONIG-MODEL-FUNCTION |
  |   0.205 | 0.000 | 32,341,840    |        124 | 0.001651 | BAYESIAN-ANALYSIS::%DO-F-MAX               |
  |   0.000 | 0.000 | 130,768       |          6 | 0.000000 | BAYESIAN-ANALYSIS::GET-VARIANCE-FOR-PARAM  |
  |   0.000 | 0.000 | 36,168,976    |          1 | 0.000000 | BAYESIAN-ANALYSIS:GET-PARAMETER-RESULTS    |
  |   0.000 | 0.000 | 32,752        |        272 | 0.000000 | MAKE-ARRAY                                 |
  |---------+-------+---------------+------------+----------+--------------------------------------------|
  |  20.771 | 0.088 | 4,271,031,008 | 50,061,845 |          | Total                                      |
- 2d-bayes-konig-model-function is consing 48 byte per call, which seems to be okay for now
- but why is it spending that much time in hessian still
- so, start to unfold this a bit by profiling what is now mostly lambdas
  #+BEGIN_SRC lisp
  (in-package #:penning-analysis)

  (f/performance-do-fit)
  (sb-profile::unprofile-all)
  (sb-profile:reset)
  (sb-profile:profile ba:get-parameter-results ba::get-variance-for-param
                      ba::hessian
                      ba::%do-f-max
                      ;fp::2d-bayes-konig-model-function
                      )

  (time
   (ba:get-parameter-results *res-2d-intrap-performance* :no-bins 20))

  #+END_SRC

- ok, so maybe do these two things:
  + change slot-value calls to array calls all the time
  + do not use a return value but a struct
- let's test this by hand first
- though, which seems to take a long time
- what I am doing ? plan:
- compare call to hand optimized version of
  2d-bayes-konig-model-function to non-optimized by calling a million
  times or so with real data
- while keeping an eye on the following:
  + same results
  + memory usage
  + execution time
- *after that:* see if we can make it even faster
- *then*, look at the likelihood funtions and see what can be done about
  them
- define function to create the array for the model 
- let's make the hand optimized model function actually work
- for that we need a model to get the parameters from
- split f/performance-do-fit into model creation and optimization function
- with that, we compare 10 million function calls:
  #+BEGIN_QUOTE
  PA> (fp::test-function)
  Evaluation took:
  0.585 seconds of real time
  0.584000 seconds of total run time (0.584000 user, 0.000000 system)
  99.83% CPU
  1,518,937,394 processor cycles
  160,006,144 bytes consed
  
  NIL
  PA> (fp::test-function2)
  Evaluation took:
  1.147 seconds of real time
  1.140000 seconds of total run time (1.128000 user, 0.012000 system)
  [ Run times consist of 0.008 seconds GC time, and 1.132 seconds non-GC time. ]
  99.39% CPU
  2,973,609,825 processor cycles
  479,999,536 bytes consed
  
  NIL
  #+END_QUOTE
- roughly half the time but still consing 16 byte per call, where though ?
- and how much does it matter ?
- first though, need to try it with static-vectors
- that works pretty well
- ok, let's integrate that into the code
- that means changing the slot-values to access to the array (maybe by
  index); where does this need to happen ?
  + [ ] priors
  + [ ] optimization function in general
- another idea would be to actually macroexpand the find-optimum
  methods, but let's look at that later
  
** TODO create likelihood function for different assumptions
*** [ ] only x values
let's see if I can do that already 
#+BEGIN_SRC lisp
(in-package #:fit-penning)




#+END_SRC
** TODO see why calculating the hessian takes pretty long
** TODO make use of provided priors
** TODO introduce other types of error assumptions
** TODO plotting methods stuff diff. than xys
** TODO org output function
this should be going into org integration, or at least a generic
version of if
** STARTED documentation
** NEEDS-TESTING get model comparison working
[2017-05-24 Wed 14:21] as the last big thing to implement, start with model comparison
*** Laplacian approximation
Based on the Laplacian approximation:
\begin{equation}
\label{eq:lap-approx}
p \left( D|M,I \right)
  \approx p ( \hat{\theta} | M,I) \mathcal{L} ( \hat{\theta} ) \left( 2\pi \right)^{M/2}(\det \mathbf{I})^{-1/2}, 
\end{equation}
where $M$ is the number of eigenvectors of $\mathbf{I}$ -- which
should be the equal to the rank of $\mathbf{I}$. The
definition of the odds ratio is:
\begin{equation}
\label{eq:odds-ratio}
O_{21} = \frac{p \left( M_2 | D,I \right)}{p \left( M_1 | D,I \right)}
       = \frac{p \left( M_2 | I \right)}{p \left( M_1 | I \right)}
         \times \frac{p \left( D | M_2, I \right)}{p \left( D| M_1, I \right)}
\end{equation}

so, what do I need here, $p(D|M,I)$ is the likelihood that can be
approximated with \ref{eq:lap-approx}. 
*** assumptions:
- for the Laplacian approximation to be close, the posteriors need to
  be uni-modal
- $M$ in equation \ref{eq:lap-approx} is equal to the rank of
  $\mathbf{I}$
  
*** logbook
- ohh, I seem to have some code already [[file:odds.lisp::(defmethod%20calculate-odds-ratio-1/2%20((model-1%20model)%20(model-2%20model)%20(data%20data)%20&key)][here]]
- but it doesn't seem to be using the laplacian approximation
- in fact, it seems as if it just evaluate the models, not sure if
  that is true, there seems to be an integral involved if my memory
  serves me correctly
- let's check if that is true after some coffee ...
- yeah, that needs to be marginalized, which is why
  \ref{eq:lap-approx} needs to be used
- so, the current implementation is not correct *-->* let's remove it
- ok, since we use the laplacian approximation, we need to specialize
  the method on something that can actually be used to calculate the
  laplacian approximation
- renamed laplacian-approximation to
  laplacian-approximation-marginal-posterior since it is a more
  accurate description
- at some point, I might have to introduce generics for the
  laplacian-approximation stuff
- ok, that seemed a bit too straight forward, so let's test this
  #+BEGIN_SRC lisp 
  (in-package #:bayesian-analysis)

  (eval-when (:compile-toplevel :load-toplevel)
    (define-data-class 1d-data (x "x") y err
        (object (source t))
      (setf x (make-array 5 :initial-contents '(-1d0 0d0 1d0 2d0 3d0)
                            :element-type 'double-float)
            y (make-array 5 :initial-contents '(2.8d0 3.1d0 3.05d0 3.2d0 3.4d0)
                            :element-type 'double-float)
            err (make-array 5 :initial-contents '(0.1d0 0.1d0 0.2d0 0.1d0 0.1d0)
                              :element-type 'double-float))))



  (define-bayesian-model (quadratic 1d-data)
      ((a :default 0.5 :min -1 :max 1 :prior :uniform  :marginalize t)
       (b :prior :uniform :default -0 :min -1 :max 1 :marginalize t)
       (c :prior :uniform :default 3 :min 2 :max 4 :marginalize t))
      (:d_i=f_i+gaussian_error_i_unequal_sigma)
      ((x) (+ (* a x) (* b x x) c)))

  (define-bayesian-model (linear 1d-data)
      ((a :default 1 :min -1 :max 1 :prior :uniform :marginalize t)
       (b :prior :uniform :default 2 :min 2 :max 4 :marginalize t))
      (:d_i=f_i+gaussian_error_i_unequal_sigma)
      ((x) (+ (* a x) b)))

  (labels ((cmd (fmt-str &rest args)
             (mgl-gnuplot:command (apply #'format nil fmt-str args))))
    (mgl-gnuplot:with-session ()
      (cmd "reset")
      (cmd "set terminal wxt enhanced font 'Georgia,8' dashed")
      (plot-result-models
       (get-parameter-results
        (ba:find-optimum (make-instance 'ba:nlopt)
                         (make-instance 'quadratic)
                         (ba:initialize-from-source '1d-data t)) :no-bins 100))
      (cmd "unset output")))


  (labels ((cmd (fmt-str &rest args)
             (mgl-gnuplot:command (apply #'format nil fmt-str args))))
    (mgl-gnuplot:with-session ()
      (cmd "reset")
      (cmd "set terminal wxt enhanced font 'Georgia,8' dashed")
      (mgl-gnuplot:plot*
       (list
        (mgl-gnuplot:data*
         (ba:plot-parameter-distribution
          (get-parameter-results
        (ba:find-optimum
         (make-instance 'ba:nlopt)
         (make-instance 'quadratic)
         (ba:initialize-from-source '1d-data t))
        :no-bins 50) 'b)
         "with lines"))) 
      (cmd "unset output")))



  (let ((data (ba:initialize-from-source '1d-data t)))
    (ba:calculate-odds-ratio-2/1
     (ba:find-optimum
      (make-instance 'ba:nlopt)
      (make-instance 'linear) data)
     (ba:find-optimum
      (make-instance 'ba:nlopt)
      (make-instance 'quadratic)
      data)))

  #+END_SRC
- this seems to make sense; need to come up with a test for this
- ok, this could be it, needs more testing, though

*** TODOs 
**** TODO come up with something to compare this too 
maybe from the book (Gregory)
** WAITING put public api in one place
file:./bayesian.lisp is probably the place to put it
** DONE introduce caching
what determines if we use use a cached value ?
- has sampling happened 
- are the input parameters the same ?

the dependent parameters need to be able to take more than one
parameter for the 2d analysis case
** DONE nlopt
since Levenberg marquardt does not work for non-uniform priors, use
nlopt to find maximum

*** code to test
setting up test code so we can test with a resonance, let's do this in
the penning-analysis package, might be easier
#+BEGIN_SRC lisp :results none
(in-package #:penning-analysis)

(defparameter *test-file* (midas:read-mpet-midas-file "/data_analysis/midas-files/20160630/run277347.mid"))

(defparameter *d*

  (tof-data:data *test-file* 1
		 :min-tof 20d0 :max-tof 50d0 :min-no-ions 3 :max-no-ions 4))
#+END_SRC


Next: example on how to use it:
#+BEGIN_SRC lisp :results none
(in-package #:penning-analysis)

(defparameter *data*
  (tof-data:data *test-file* 1
		 :min-tof 20d0
		 :max-tof 50d0
		 :min-no-ions 1
		 :max-no-ions 5))

(let ((params (fp:get-init-params-from-midas-file
	       ,*test-file* :om-c-deviation 4d0
	       ;:om-c-prior (make-instance 'ba:gaussian-prior :mu 3.222541d7 :sigma 10d0)
	       :rho-m0-sampler '(ba:gaussian-sampler :sigma 1d-5)
	       :om-c-sampler '(ba:gaussian-sampler :sigma 1d0)
	       :tof-offset-min 0.1d0 :tof-offset-max 1d0 :tof-offset 0.5d0
	       :rho-m0 4d-4
	       :rho-m0-min 2d-4
	       :rho-m0-max 6d-4)))
  (defparameter *res-nlopt*
    (ba:find-optimum
     (make-instance 'ba:nlopt :algorithm nlopt:+nlopt_ln_neldermead+)
     (apply #'make-instance 'fp:bayes-konig params)
     (ba:initialize-from-source 'fp:bayes-tof *data*))))

(let ((params (fp:get-init-params-from-midas-file
	       ,*test-file* :om-c-deviation 4d0
	       ;:om-c-prior (make-instance 'ba:gaussian-prior :mu 3.222541d7 :sigma 10d0)
	       :rho-m0-sampler '(ba:gaussian-sampler :sigma 1d-5)
	       :om-c-sampler '(ba:gaussian-sampler :sigma 1d0)
	       :tof-offset-min 0.1d0 :tof-offset-max 1d0 :tof-offset 0.5d0
	       :rho-m0 4d-4
	       :rho-m0-min 2d-4
	       :rho-m0-max 6d-4)))
  (defparameter *res-nlopt-low-error*
    (ba:find-optimum
     (make-instance 'ba:nlopt :algorithm nlopt:+nlopt_ln_neldermead+)
     (apply #'make-instance 'fp:bayes-konig params)
     (ba:initialize-from-source 'fp:bayes-tof *data*))))


(let ((params (fp:get-init-params-from-midas-file
	       ,*test-file* :om-c-deviation 4d0
	       ;:om-c-prior (make-instance 'ba:gaussian-prior :mu 3.222541d7 :sigma 10d0)
	       :rho-m0-sampler '(ba:gaussian-sampler :sigma 1d-5)
	       :om-c-sampler '(ba:gaussian-sampler :sigma 1d0)
	       :tof-offset-min 0d0 :tof-offset-max 2d0
	       :rho-m0 4d-4
	       :rho-m0-min 2d-4
	       :rho-m0-max 6d-4)))
  (defparameter *res-mcmc*
    (ba:find-optimum
;     (make-instance 'ba:nlopt :algorithm nlopt:+nlopt_ln_neldermead+)
     (make-instance 'ba:metropolis-hastings :no-iterations 100000)
     (apply #'make-instance 'fp:bayes-konig params)
     (ba:initialize-from-source 'fp:bayes-tof *data*))))




(labels ((cmd (fmt-str &rest args)
	   (mgl-gnuplot:command (apply #'format nil fmt-str args))))
  (mgl-gnuplot:with-session ()
    (cmd "reset")
    (cmd "set terminal wxt enhanced font 'Georgia,8' dashed")
    (cmd "set title 'mcmc'")
    (ba:plot-result (ba:get-parameter-results *res-nlopt*))
    (cmd "unset output")))

(let ((ba::*use-sigma-f-min/max* 4))
  (labels ((cmd (fmt-str &rest args)
	     (mgl-gnuplot:command (apply #'format nil fmt-str args))))
    (mgl-gnuplot:with-session ()
      (cmd "reset")
      (cmd "set terminal wxt enhanced font 'Georgia,8' dashed")
      (ba:plot-parameter-distribution
       (ba:get-parameter-results *res-nlopt* :start 2000 :no-bins 50) 'fp::tof-offset)
      (cmd "unset output"))))


(labels ((cmd (fmt-str &rest args)
	   (mgl-gnuplot:command (apply #'format nil fmt-str args))))
  (mgl-gnuplot:with-session ()
    (cmd "reset")
    (cmd "set terminal wxt enhanced font 'Georgia,8' dashed")
    (mgl-gnuplot:plot*
     (list
      (mgl-gnuplot:data*
       (map 'list #'identity (ba::laplacian-approximation-marginal-posterior *res* 'fp::rho-m0 100 :on-center nil))
       "with steps"))) 
    (cmd "unset output")))







(test-gaussian)


(progn
  (defun test-gaussian ()
    (labels ((cmd (fmt-str &rest args)
	       (mgl-gnuplot:command (apply #'format nil fmt-str args))))
      (mgl-gnuplot:with-session ()
	(cmd "reset")
	(cmd "set terminal wxt enhanced font 'Georgia,8' dashed")
	(mgl-gnuplot:plot*
	 (list
	  (mgl-gnuplot:data*
	   (let+ ((model (ba:copy-object (ba:model *res*)))
		  ((&slots fp::om-c-min fp::om-c-max) model)
		  (no-steps 200)
		  (prior (aref (ba::log-of-all-priors-array model) 0)))
	     (iter
	       (with diff = (- fp::om-c-max fp::om-c-min))
	       (for x from fp::om-c-min to fp::om-c-max by (/ diff no-steps))
	       (setf (fp::om-c model) x)
	       (collect (list (- x (+ fp::om-c-min (/ diff 2)))
			      (funcall prior)))))
	   "with lines"))) 
	(cmd "unset output")))))
#+END_SRC
*** logbook
- [2017-05-16 Tue 10:33] continuing logbook here
- *problem:* the posterior distribution calculated for the laplacian
  seems to be dependent on the range -- at least for the tof-offset and rho-m0
- *also:* the determinant of the Fisher information matrix changes sign
- actually, let's first make sure that it still works at all 
- no, not really -- wish I had made a commit of the unfinished version
  of it
- so, what seems to be going on ? 
- firstly, it finds the correct minimum
- but the distribution for om-c is now flat (at zero)
- no, first, try to see what happens, to the fit, when fixing a
  parameter
  #+BEGIN_SRC lisp
  (in-package :penning-analysis)


  (labels ((cmd (fmt-str &rest args)
             (mgl-gnuplot:command (apply #'format nil fmt-str args)))
           (get-params ()
             (fp:get-init-params-from-midas-file *test-file* :om-c-deviation 10d0
                                                 :om-c-sample-sigma 0.5d0
                                                 :tof-offset-min -1d0
                                                 :tof-offset 0d0
                                                 :tof-offset-marginalize nil
                                                 :tof-offset-max 1d0
                                                 :tof-offset-sample-sigma 0.01d0
                                                 :rho-m0-marginalize t
                                                 :rho-m0-sample-sigma 1d-5)))
    (let+ ((data)
           (plots
            (iter
              (with k = (apply #'make-instance 'fp:bayes-konig (get-params)))
              (for tof-offset from -5d0 to 5d0 by 1d0)
              (setf (fp::tof-offset k) tof-offset)
              (for opt = (ba:find-optimum (make-instance 'ba:nlopt) k
                                          (ba:initialize-from-source 'fp:bayes-tof *d*)))
              (for res = (ba:get-parameter-results opt))
              (for (d input results) = (ba:plot-result-model res :enclose-in-plot nil))
              (setf data d)
              (collect results))))
      (mgl-gnuplot:with-session ()
        (cmd "reset")
        (cmd "set terminal x11 enhanced font 'Georgia,8' dashed")
        (mgl-gnuplot:plot*
         (append (list data) plots))
        (cmd "unset output"))))

  (labels ((get-params ()
             (fp:get-init-params-from-midas-file *test-file* :om-c-deviation 10d0
                                                 :om-c-sample-sigma 0.5d0
                                                 :rho-m0 1d-4
                                                 :tof-offset-marginalize nil)))
                                                 (iter
      (with k = (apply #'make-instance 'fp:bayes-konig (get-params)))
      (for tof-offset from -1d0 to 1d0 by 0.1d0)
      (setf (fp::tof-offset k) tof-offset)
      (for opt = (ba:find-optimum (make-instance 'ba:nlopt) k
                                  (ba:initialize-from-source 'fp:bayes-tof *d*)))
      (collect (list (ba::nlopt-result opt)
                     (ba::f-val opt)
                     tof-offset))))
  #+END_SRC

  #+RESULTS:
  : unset output
- ok, that seems to make sense to me
- let's look at copy object and see if we can amend it so it updates specific values
- [2017-05-17 Wed 10:30] that made it work somehow
- now, the determinant is still a problem ... let's fix that
- [2017-05-18 Thu 16:10] seems, that the determinant isn't really a
  problem (just taking the absolute, seems to work) and the inverse is
  working now as well
- commiting: [[orgit-rev:~/phd/src/penning-analysis.project/bayesian-analysis/::56ae9f2][~/phd/src/penning-analysis.project/bayesian-analysis/ (magit-rev 56ae9f2)]]
- *next thing to do*, introduce proper gaussian prior
- that probably involves more parameters, as min/max isn't enough
- [2017-05-19 Fri 09:44] introduced gaussian prior
- commit: [[orgit-rev:~/phd/src/penning-analysis.project/bayesian-analysis/::bb39265][~/phd/src/penning-analysis.project/bayesian-analysis/ (magit-rev bb39265)]]
- now, let's plot the priors to see that the gaussian actually looks
  like it is supposed to look like (and maybe the jeffreys as well ...)
- okay then, there was a small mistake in the gaussians
- commit: [[orgit-rev:~/phd/src/penning-analysis.project/bayesian-analysis/::581f657][~/phd/src/penning-analysis.project/bayesian-analysis/ (magit-rev 581f657)]]
- need to rework the prior mechanism into something that is more
  generic, maybe make a class of it
- probably the way to go: method that specializes either on symbol
  (:certain, :jeffreys, :uniform) or object, like gaussian
- [2017-05-23 Tue 13:55] implementing parameter results for nlopt results
- so, how do I determine min max for nlopt results ? For mcmc results
  that was easy, since we could just take the min/max of the iteration values
- let's start by using the prior range and then maybe think of something else
- mmmh, laplacian-approximation-marginal-posterior doesn't work anymore for rho-m0 ?
- ok, I'm probably not copying the model and then the parameter set
  last for calculating the binned data stays
- let's see where I actually set parameters
- laplacian-approximation-marginal-posterior sets slots, but it makes copies, let's test
  if that could be the problem:
  #+BEGIN_SRC lisp :results none
  (in-package #:penning-analysis)



  (labels ((cmd (fmt-str &rest args)
             (mgl-gnuplot:command (apply #'format nil fmt-str args))))
    (mgl-gnuplot:with-session ()
      (cmd "reset")
      (cmd "set terminal wxt enhanced font 'Georgia,8' dashed")
      (ba::laplacian-approximation-marginal-posterior *res* 'fp::rho-m0 100 :on-center nil)
      (ba::laplacian-approximation-marginal-posterior *res* 'fp::om-c 100 :on-center nil)
      (mgl-gnuplot:plot*
       (list
        (mgl-gnuplot:data*
         (map 'list #'identity (ba::laplacian-approximation-marginal-posterior *res*
                                                            'fp::tof-offset 300
                                                            :on-center nil))
         "with steps"))) 
      (cmd "unset output")))
  #+END_SRC
- the above works w/o problems, so that shouldn't be it
- ok, it is probably the median setting that I do with :on-center t
- ok, solved that problem, now, if I compare om-c found with mcmc to
  the one found with nlopt, they differ by two Hz, wtf ??
- could this be a binning thing ?
- doesn't depend (that much) on number of bins
- ok, now I'm confused, the plot says exactly the same thing
- yeah, that was stupid, it's because the plots are offset differently
  as they have a different range -- *or are they* 
  #+BEGIN_SRC lisp :results none
  (-
   (ba:median
    (ba:get-parameter-info
     (ba:get-parameter-results *res-mcmc* :start 2000 :no-bins 100 :start 1000) 'fp:om-c))
   (ba:median
    (ba:get-parameter-info
     (ba:get-parameter-results *res-nlopt* :start 2000 :no-bins 100 :start 10000) 'fp:om-c)))


  (list
   (ba:absolute-error
    (ba:get-parameter-info
     (ba:get-parameter-results *res-mcmc* :start 2000 :no-bins 100 :start 1000
                               :confidence-level 0.9d0) 'fp:om-c))
   (ba:absolute-error
    (ba:get-parameter-info
     (ba:get-parameter-results *res-nlopt* :start 2000 :no-bins 100 :start 10000
                               :confidence-level 0.9d0) 'fp:om-c)))

  #+END_SRC
- let's get back to that, but first I need to have some accessor
  function to for ease of use:
- o.k., with that is seems obvious that is quite a difference 
- why then is the plot the same *--->* what am I doing when plotting ? 
- just for giggles, start changing the binning *->* that made it even worse
- ok, maybe that is actually what it is ... the fits are slightly different
- I should compare it to what LM gives as an answer to be sure it is actually ok
  #+BEGIN_SRC lisp
  (defparameter *test-file* (midas:read-mpet-midas-file "/data_analysis/midas-files/20160630/run277347.mid"))

  (defparameter *data*
    (tof-data:data *test-file* 1
                   :min-tof 20d0
                   :max-tof 50d0
                   :min-no-ions 1
                   :max-no-ions 5))

  (let ((params (fp:get-init-params-from-midas-file
                 ,*test-file* :om-c-deviation 4d0
                 :rho-m0-sampler '(ba:gaussian-sampler :sigma 1d-5)
                 :om-c-sampler '(ba:gaussian-sampler :sigma 1d0)
                 :tof-offset-min 0d0 :tof-offset-max 2d0
                 :rho-m0 4d-4
                 :rho-m0-min 2d-4
                 :rho-m0-max 6d-4)))
    (defparameter *res-nlopt*
      (ba:find-optimum
       (make-instance 'ba:nlopt :algorithm nlopt:+nlopt_ln_neldermead+)
       (apply #'make-instance 'fp:bayes-konig params)
       (ba:initialize-from-source 'fp:bayes-tof *data*))))



  (let+ ((lm-res (fp:om-c
                  (pa:fit-model
                   (pa:fit-run *test-file*
                               (make-instance 'pa:run-constraints :tof-range '(20d0 50d0)
                                                                  :no-ion-range '(1 5)
                                                                  :tof-bin-width 0.2d0) 
                               'fit-penning::konig :fit-rho-m0 t :rho-m0 5d-4 :om-m 38327.430373795476d0))))
         (p-results (ba:get-parameter-results *res-nlopt* :start 2000 :no-bins 30 :start 10000))
         (nl-res (ba:median (ba:get-parameter-info p-results 'fp:om-c))))
    (values (/ (- lm-res nl-res)  (ba:absolute-error (ba:get-parameter-info p-results 'fp:om-c)))))
  #+END_SRC

  #+RESULTS:
  : -0\.07924184698329063d0

- ok, I can live with that
** CANCELED introduce gsl fitting as algorithnm to solve for parameters (and model comparison)
*** logbook
- let's start with branching this
- then, where do I need to get the gsl functions from ?
- ok, copied over the gsl cffi functions into gsl-cffi
- let's start by moving the fit function over to bayesian
- maybe I can actually separate the model creation from the fitting
  part somehow ? Mee, probably takes too long right now
- so, copyied over what -- in theory -- could be a complete set of the
  functions I need ..
- okay, problems when compiling models, seems to have to do with the
  y_i function names, odd number of args to setf ? --> yup, that's true
- ok, that is at least compiling now
- sending stuff to gsl seems to work, testing quadratic fitting
- commited to git
- next: need to make things nicer to access 
- first, introduce global constants for error and max no. iterations
- introduce wrapper around fit function and rename it to lev-mar-max-like ...
- created macro in gsl-cffi to take care of the nitty gritty cffi stuff
- seems to work, now collect proper results, model the class on
  gsl-fitting for now
- mmh, might actually be better to be inspired by what I do in
  bayesian-analys2is for now and then create code that bridges the two
  worlds, i.e.: create gsl-fitting results from bayesian-analysis
  objects to be used in the analysis code elsewhere
- i should be able to use the api already set up for algoritms in
  bayesian-analysis
- may be, the existing algorithm.lisp in two parts to reflect the fact
  that there will be two different algorithms
- actually, it should fit into mcmc.lisp
- ok, done that
- now what ? --> build profile function
- need fisher information matrix -> copy over from penning-analysis
- actually, first: fulfill bayesian-analysis api
- what is still to be fulfilled ? 
- where do I find out ? -> bayesian.lisp ? *no*, not really
- algorithm.lisp -> that looks better
- ok, for the lapclacian approx., the maximization is done over prior
  x likelihood, what does that mean for non uniform priors ? 
- levenberg-marquardt is just maximizing the likelihood
- assuming (I'm pretty sure) flat priors which sucks 
- o.k., it should be possible to minimize $\chi^2/2 - \ln \left[ p
  \left( \theta,\phi | M,I \right) \right]$
- but, to be able to minimize this I will have to put it into the
  minization routine I am using and that might not work with gsl
- [2017-04-27 Thu 13:49] returning to work on this
- well, let's see what I wanted to do ...
- right, wanted to use the square root: $\sqrt{\chi^2/2 - \ln \left[ p
  \left( \theta,\phi | M,I \right) \right]}$ to minimize to get around
  the fact that minimization libraries usually take $\left(
  f_i(\vec{x})-y_i\right)/\sigma_i$ as input
- using member of model super class [[file:model.lisp::(log-of-all-priors%20:accessor%20log-of-all-priors%20:initarg%20:log-of-all-priors][log-of-all-priors]] for this 
- shit, fuck, fuck fuck, that also doesn't work since don't give
  $\chi$ to the minimization routine but rather $\chi_i$ so to speak
- that leaves me with implementing my own minimization routine ... again
- give lisp a chance:
- [2017-04-27 Thu 15:54] let's see if we can't find a decent lisp
  Levenberg-Marquardt minimizer and modify it for our purposes -- or
  find alternatives
  - nelder mead
- [2017-04-28 Fri 11:07] a new day, let's see how it goes today 
- so, looking into NLopt instead of gsl to do the minimization
- this leaves me to calculate the Fisher information matrix myself
  ... let's see what gsl has to offer for that
- is this called the Hessian or Jacobian :: it is the *Hessian*
- so, gsl gives /gsl_deriv_central/ (among others), which should be good
  enough to do this as the Fisher information matrix is defined as:
  
  \begin{equation}
  \label{eq:fisher-information}
  \mathrm{I}_{\alpha\beta} =
     -\frac{\partial^2}{\partial\theta_{\alpha}\partial\theta_{\beta}}
        \ln \left[ p(\theta|M,I)\mathcal{L}(\theta) \right]
  \end{equation}

- ok, gsl only differentiates in one direction, so that might not cut
  it
- ok, after a long, long search I've decided to probably implement the
  hessian by myself using the complex-step alg.
- [2017-04-29 Sat 12:24] no, that (very likely) won't work for ToF
  function, as it involves an integral
- o.k., let's write this for the bayesian model objects
- written first try at hessian function for model objects
- now, need to get the likelihood, how did that work again 
- getting hessian seems to work, let's see if we can invert it ...
- *problem*, the values I calculate do not line up with what gsl says
  (for the covariance matrix). In fact, the diagonal is zero for the
  easiest case.
- how can this be ? 
- O.k. -- there probably was an implementation error somewhere
  ... getting almost (on the order of 1d-10) the same answer as with
  gsl
- *for tomorrow*, refactor parameter-result to contain a result-model
- then write fisher-information matrix functionality
- include NLopt in docker image
- implement ffi for nlopt
- [2017-05-02 Tue 10:53] starting with the above
- thing is, putting the result model in the super class doesn't really
  make sense for mcmc, does it ?
- the classes are set up for using get-parameter-results for this
- so, implement that first, after making a commit
- ok, the names I came up with are total bogus, so let's fix that now
- renaming parameter-result to optimization-result
- let's see if that worked
- at least it compiles
- [2017-05-12 Fri 08:36] so, this works now, let's apply it to penning
  trap measurements to see if it still works
- optimizing penning trap data works (and with ok speed it seems,
  nothing is optimized on the lisp side, yet)
- [2017-05-16 Tue 10:28] implemented first version of laplacian
  approximation, it does seem to work well for om-c, but not so much
  for the tof-offset for example
- ok. continuing this under its own heading
  
*** ok, let's look at the second best option that is actually easier to implement
An approximate Hessian, that might be susceptible to rounding errors,
is given by:
\begin{equation}
\label{eq:approximate-hessian}
h_{j,k}=\frac{1}{4\delta_j\delta_k}
        \left\{\left[
                 f \left(\mathbf{\theta}+\delta_{j}\mathbf{e}_j + \delta_k\mathbf{e}_k \right)
                 - f\left(\mathbf{\theta}+\delta_{j}\mathbf{e}_j - \delta_k\mathbf{e}_k \right)
                \right] 
                -
                \left[
                 f \left(\mathbf{\theta}-\delta_{j}\mathbf{e}_j + \delta_k\mathbf{e}_k \right)
                 - f\left(\mathbf{\theta}-\delta_{j}\mathbf{e}_j - \delta_k\mathbf{e}_k \right)
                \right] 
        \right\}
\end{equation}

That should be easy enough to implement. But what $\delta$ do we use ?
Seems Ridout has an answer for that as well ...

Optimal step size: 
\begin{equation}
\label{eq:optimal-stepsize}
\epsilon^{1/4}\theta,
\end{equation}

where $\epsilon$ is the machine accuracy (long-float-epsilon in common
lisp)

with these two things in mind, it should be straight forward to
implement this. 





*** justification for minization 
so, why do I think I can minimize:


\begin{equation}
\label{eq:min-lnchi}
\min_{\phi}\left\{ \chi^2/2 - \ln \left[ p \left( \theta,\phi | M,I \right) \right]  \right\}
\end{equation}

The marginal posterior for a parameter in the Laplacian
approximation is given by:
  
\begin{equation}
\label{eq:posterior}
p \left( \theta | D, M, I \right) \propto
f\left( \theta \right)
        \left[
        \det \mathrm{I}\left( \theta \right)
        \right]^{-1/2}, 
\end{equation}

where the /profile/ function $f \left( \theta \right)$ is defined as:

\begin{equation}
\label{eq:profile}
f \left( \theta \right) = \max_{\phi}p \left( \theta,\phi|M,I \right)\mathcal{L} \left( \theta, \phi \right). 
\end{equation}

Assuming that the likelihood is given by a multivariate Gaussian,
which is (approximately) true for a unimodal posterior with enough
samples, the maximization can be rewritten as the minimization seen
above. 


*** things to integrate
- [X] gsl functions
- [X] building wrapper functions to sent stuff to gsl
- [ ] 
*** things to fix
- eval-when accessors for iteration as it does not compile directly,
  or split it into two files
*** code
**** starting to test the gsl fitting functionality
#+BEGIN_SRC lisp :results none
(in-package #:bayesian-analysis)

(eval-when (:compile-toplevel :load-toplevel)
  (define-data-class 1d-data (x "x") y err
      (object (source t))
    (setf x (make-array 5 :initial-contents '(-1d0 0d0 1d0 2d0 3d0)
			  :element-type 'double-float)
	  y (make-array 5 :initial-contents '(2.8d0 3.1d0 3.05d0 3.5d0 3.4d0)
			  :element-type 'double-float)
	  err (make-array 5 :initial-contents '(0.1d0 0.1d0 0.2d0 0.1d0 0.1d0)
			    :element-type 'double-float))))



(define-bayesian-model (quadratic 1d-data)
    ((a :default 0.5 :min -1 :max 1 :prior-type :uniform :sample-sigma 0.1d0 :marginalize t)
     (b :prior-type :uniform :default -0.5 :min -4 :max 4 :marginalize t)
     (c :prior-type :uniform :default 2 :min 2 :max 4 :sample-sigma 0.1d0 :marginalize t))
    (:d_i=f_i+gaussian_error_i_unequal_sigma)
    ((x) (+ (* a x) (* b x x) c)))

(define-bayesian-model (linear 1d-data)
    ((a :default 1 :min -1 :max 1 :prior-type :uniform :sample-sigma 0.1d0 :marginalize t)
     (b :prior-type :uniform :default 2 :min 2 :max 4 :sample-sigma 0.1d0 :marginalize t))
    (:d_i=f_i+gaussian_error_i_unequal_sigma)
    ((x)
      (+ (* a x) b)))

#+END_SRC

**** fisher information matrix calculations
#+BEGIN_SRC lisp
(in-package :bayesian-analysis)

(defun get-optimal-delta (model &optional (epsilon long-float-epsilon epsilon-given-p))
  (let+ (((&slots model-parameters-to-marginalize) model))
    (iter
      (for param in model-parameters-to-marginalize)
      ;; fixme: should look up what happens if the value is below the
      ;; machine accuracy
      (collect (list param
		     (if epsilon-given-p
			 epsilon
			 (* (expt epsilon 0.25d0)
			    (slot-value model param))))))))


(defun hessian (func model params.delta)
  "Calculate the hessian matrix for FUNC, where FUNC is a function
object (closure) that depends on MODEL. PARAMS.DELTA is a list
of (PARAMETER-SLOT DELTA), where PARAMETER-SLOT is the name of a slot
that was marginalized and DELTA is the optimal delta for that
variable.
"
  (let+ ((dim (length params.delta))
	 ;; fixmee: type information here
	 (ret-val (make-array (list dim dim))))
    (labels ((param (i) (first (nth i params.delta)))
	     (delta (i) (second (nth i params.delta)))
	     (d (param delta)
	       (incf (slot-value model param) delta))
	     (h-j-k (param-j delta-j param-k delta-k)
	       (let ((a 0d0) (b 0d0)
		     (c 0d0) (d 0d0))
		 (d param-j delta-j) (d param-k delta-k)
		 (setf a (funcall func))
		 (d param-k (- (* 2d0 delta-k)))
		 (setf b (funcall func))
		 (d param-j (- (* 2d0 delta-j)))
		 (setf d (funcall func))
		 (d param-k (* 2d0 delta-k))
		 (setf c (funcall func))
		 (/ (- (- a b)
		       (- c d))
		    (* 4d0 delta-j delta-k)))))
      (iter
	(for j from 0 below dim)
	(iter
	  (for k from j below dim)
	  (let+ ((grad (h-j-k (param j) (delta j)
			      (param k) (delta k))))
	    (setf (aref ret-val j k) grad
		  (aref ret-val k j) grad))))
      ret-val)))



(defmethod fisher-information-matrix ((model model) &key (epsilon long-float-epsilon))
  (let+ (((&slots log-of-all-priors log)))))

(defun test-approx-hessian ()
  (let+ ((input-model (make-instance 'linear))
	 (data (initialize-from-source '1d-data t))
	 ((&slots model)
	  (find-optimum (make-instance 'levenberg-marquardt) input-model data))
	 ((&slots log-of-all-priors) model)
	 (likelihood (initialize-likelihood model data))
	 ((&slots varying/log-of-likelihood constant/log-of-likelihood) likelihood))
    (labels ((fun ()
	       (+
		(funcall varying/log-of-likelihood)
		(funcall constant/log-of-likelihood)
		(funcall log-of-all-priors))))
      (progn ;math-utils:invert-matrix
       (hessian #'fun model
      		(get-optimal-delta model))))))


(defun test ()
  (let+ ((model (make-instance 'quadratic))
	 (data (initialize-from-source '1d-data t))
	 ((&slots log-of-all-priors) model)
	 (likelihood (initialize-likelihood model data)))
    (nlopt:optimization likelihood (make-instance 'nlopt:config))))

(let+ (((&values no model) (test)))
  (defparameter *result* model))


((&slots model)
 (find-optimum (make-instance 'levenberg-marquardt) input-model data))

#+END_SRC
**** testing stuff
#+BEGIN_SRC lisp 
(in-package #:bayesian-analysis)


(defun test-approx-hessian ()
  (let+ ((model (make-instance 'linear))
	 (data (initialize-from-source '1d-data t))
	 ((&slots result-model)
	  (optimize (make-instance 'levenberg-marquardt) model data))
	 ((&slots log-of-all-priors) result-model)
	 (likelihood (initialize-likelihood result-model data))
	 ((&slots varying/log-of-likelihood constant/log-of-likelihood) likelihood))
    (labels ((fun ()
	       (+
		(funcall varying/log-of-likelihood)
;		  (funcall constant/log-of-likelihood)
;		  (funcall log-of-all-priors)
		)))
      (math-utils:invert-matrix
       (hessian #'fun result-model
		(get-optimal-delta result-model))))))


(test-approx-hessian)





#+END_SRC
**** testing with resonance
- doing this in package penning-analysis 'cause it is easier
** DONE bin laplacian approximation better
maybe can use errors (x 6) from the fisher information matrix to
calculate a more sensible region for the distributions than min -> max
*** logbook
- [2017-05-25 Thu 10:21] ok, that seems to work now
- testeing to not use the absolute value when calculating the error
  from the covariance matrix ... let's see if that works out
** CANCELED make konig work faster
this needs the fit-penning package to provide the konig model
*** prerequisites
- tof data
  #+BEGIN_SRC lisp :results none
  (in-package #:fit-penning)
  (defparameter *d*
    (tof-data:data (midas:read-mpet-midas-file "/data_analysis/midas-files/20160708/run280463.mid") 1
                   :min-tof 20d0 :max-tof 50d0 :max-no-ions 2))
#+END_SRC
- parameters
  #+BEGIN_SRC lisp :results none
  (in-package #:fit-penning)
  (defparameter *no-iterations* 20000)
  #+END_SRC
- and then some results to test stuff with
  #+BEGIN_SRC lisp :results none
  (in-package #:fit-penning)

  (time
   (defparameter *mcmc-konig-result/1*
     (ba:optimize (make-instance 'ba:metropolis-hastings :no-iterations *no-iterations*)
                              (make-instance 'bayes-konig
                                             :om-c (* 2 pi 5556259.7d0)
                                             :om-c-min (* 2 pi (- 5556259.7d0 30d0))
                                             :om-c-max (* 2 pi (+ 5556259.7d0 30d0))
                                             :om-c-sample-sigma 0.1d0
                                             :om-m (* 2 pi 6112.3d0)
                                             :om-c-bin-width 0.01d0
                                             :e-0-sample-sigma 1d-1
                                             :e-0-bin-width 0.1d0
                                             :tof-offset-sample-sigma 0.01d0
                                             :tof-offset-bin-width 0.01
                                             :rho-m0-bin-width 1d-6
                                             :rho-m0-sample-sigma 1d-5
                                             :q 13d0)
                              (ba:initialize-from-source 'bayes-tof *d*))))
  #+END_SRC

*** let's plot it to make sure it worked
- iterations
  #+BEGIN_SRC lisp :results none
  (in-package #:fit-penning)

  (labels ((cmd (fmt-str &rest args)
             (mgl-gnuplot:command (apply #'format nil fmt-str args))))
    (mgl-gnuplot:with-session ()
      (cmd "reset")
      (cmd "set terminal x11 enhanced font 'Georgia,8' dashed")
      (ba:plot-iteration-values
       ,*mcmc-konig-result/1*
       :params-to-plot '(om-c)
       :start 0 :every 10)
      (cmd "unset output")))
  #+END_SRC
- distributions
  #+BEGIN_SRC lisp :results none
  (in-package #:fit-penning)

  (labels ((cmd (fmt-str &rest args)
               (mgl-gnuplot:command (apply #'format nil fmt-str args))))
      (mgl-gnuplot:with-session ()
        (cmd "reset")
        (cmd "set terminal x11 enhanced font 'Georgia,8' dashed")
        (ba:plot-parameter-distribution
         (ba:get-parameter-results *mcmc-konig-result/1* :no-bins 25 :start 1000) 'om-c)
        (cmd "unset output")))
  #+END_SRC

  #+RESULTS:
- result model
  #+BEGIN_SRC lisp :results none
  (in-package #:fit-penning)

  (labels ((cmd (fmt-str &rest args)
             (mgl-gnuplot:command (apply #'format nil fmt-str args))))
    (mgl-gnuplot:with-session ()
      (cmd "reset")
      (cmd "set terminal x11 enhanced font 'Georgia,8' dashed")
      (ba:plot-result-model (ba:get-parameter-results
  			   ,*mcmc-konig-result/1* 
  			   :start 1500))
      (cmd "unset output")))
#+END_SRC
*** let's get a profile base-line
#+BEGIN_SRC lisp :package fit-penning
(in-package #:fit-penning)









#+END_SRC

#+RESULTS:
: *D*
** CANCELED make 2d work
after loosing a lot of work by being stupid with git, let's do this again
#+BEGIN_SRC lisp
(in-package #:bayesian-analysis)


(defparameter *data* (initialize-from-source '1d-gaussian t))

(defparameter *test-result*
  (optimize (make-instance 'metropolis-hastings :no-iterations 5000)
			(make-instance 'test-mean) *data*))

(labels ((cmd (fmt-str &rest args)
	   (mgl-gnuplot:command (apply #'format nil fmt-str args))))
  (mgl-gnuplot:with-session ()
    (cmd "reset")
    (cmd "set terminal x11 enhanced font 'Georgia,8' dashed")
    (ba:plot-iteration-values *test-result*
			      :params-to-plot '(a-1 a-2) :start 0 :every 1)
    (cmd "unset output")))


(labels ((cmd (fmt-str &rest args)
	   (mgl-gnuplot:command (apply #'format nil fmt-str args))))
  (mgl-gnuplot:with-session ()
    (cmd "reset")
    (cmd "set terminal x11 enhanced font 'Georgia,8' dashed")
    (ba:plot-likelihood *test-result* :start 0 :every 10)
    (cmd "unset output")))

(labels ((cmd (fmt-str &rest args)
	   (mgl-gnuplot:command (apply #'format nil fmt-str args))))
  (mgl-gnuplot:with-session ()
    (cmd "reset")
    (cmd "set terminal x11 enhanced font 'Georgia,8' dashed")
    (ba:plot-parameter-distribution (ba:get-parameter-results *test-result* :start 1500 :no-bins 10) 'a-2)
    (cmd "unset output")))

(defparameter *param-results* (ba:get-parameter-results *test-result* :start 5000 :no-bins 10))

(labels ((cmd (fmt-str &rest args)
	   (mgl-gnuplot:command (apply #'format nil fmt-str args))))
  (mgl-gnuplot:with-session ()
    (cmd "reset")
    (cmd "set terminal x11 enhanced font 'Georgia,8' dashed")
    (plot-data *data*)
    (cmd "unset output")))


#+END_SRC

aha! seems that when using a jeffreys prior, things go wrong ... mmmh,
interesting. Oh well, if you take the log of a multiplication it
becomes a sum.

[2017-03-10 Fri 15:55] after playing around with it for a while, it
seems to be really messy, so heres what I should 
- introduce the ability to plot the resonance
- see if it actually fits when the iteration values imply that it does
  (I might be misleading myself)
- if it does, investigate why it fits the "bad" data a lot better than
  the good data
- try fitting some hard resonances 
  + this will proably involve a two isotope fit, how about we try that
  + first, let's use an intrap fit
  + also, fixing rho-m0 makes a lot of sense
- [2017-05-25 Thu 12:09]     

*** it is working without the amplitude parameter
which leaves me to believe that either the probability distribution is
wrong or I need to play with the parameters more ...
** CANCELED straight integration
meaning marginalization should also just work. The issue could be that
I can't do the integral because double-float won't be able to hold
numbers small enough

let's start by looking at the pdf of a model solved with metropolis
hastings:
#+BEGIN_SRC lisp
(in-package #:bayesian-analysis)


(defparameter *test-file*
  (midas:read-mpet-midas-file "/home/renee/phd/data_analysis/201607CD_In/midas-files/20160630/run277347.mid"))

(defparameter *test-file2*
  (midas:read-mpet-midas-file
   "/home/renee/phd/data_analysis/first-nrich-reevaluated/first-nrich-midas-files/20101210/run088167.mid"
   :om-m (* 2 pi 6100) :om-c (* 2 pi 10035195d0) :charge 15d0))





(defun do-metrohastings (file &key (use-nlopt-for-initial t) (no-iterations 10000) (no-bins 100)
				   (min-tof 5) (max-tof 25)
				   (min-ions 1) (max-ions 1))
  (let+ ((init-params (fp:get-init-params-from-midas-file file 20d0
							  :om-c-sample-sigma 5d0
							  :separation 10d0
							  :rho-m0-max 1d-2
							  :tof-offset-marginalize t
							  :tof-offset-sample-sigma 1d0
							  :tof-offset-min -20d0))
	 (initial-model2 (apply #'make-instance 'fp::bayes-double-konig init-params))
	 (initial-model (apply #'make-instance 'fp::bayes-konig init-params))
	 (data (ba:initialize-from-source 'fp:bayes-tof 
					  (tof-data:data file 1
							 :min-tof min-tof :max-tof max-tof
							 :min-no-ions min-ions :max-no-ions max-ions)))
	 (nlopt-result (ba:find-optimum (make-instance 'ba:nlopt :max-time 5d0) initial-model data))
	 (nlopt-result2 (ba:find-optimum (make-instance 'ba:nlopt :max-time 5d0) initial-model2 data))
	 (mcmc-result (ba:find-optimum (make-instance 'ba:metropolis-hastings :no-iterations no-iterations)
				       (if use-nlopt-for-initial (ba:model nlopt-result) initial-model)
				       data))
	 (mcmc-result2 (ba:find-optimum (make-instance 'ba:metropolis-hastings :no-iterations no-iterations)
					(if use-nlopt-for-initial (ba:model nlopt-result2) initial-model2)
					data)))
    (values mcmc-result mcmc-result2 data nlopt-result nlopt-result2)))



(let+ ((no-bins 100)
       ((&values mcmc-result mcmc-result2 data)
	(do-metrohastings vanessa-reanalysis::*rb98-added-runs* :max-tof 28 :no-iterations 50000
	  :use-nlopt-for-initial t)))
  (ba::calculate-odds-ratio-1/2
   (ba:model (ba:get-parameter-results mcmc-result2 :no-bins no-bins))
   (ba:model (ba:get-parameter-results mcmc-result :no-bins no-bins))
   data))











(let+  (((&values mcmc-result mcmc-result2)
	 (do-metrohastings vanessa-reanalysis::*rb98-added-runs* :max-tof 50 :no-iterations 10000
	   :use-nlopt-for-initial t)
	 ;; (do-metrohastings *test-file2* :max-tof 50 :no-iterations 50000
	 ;;   :use-nlopt-for-initial t)
	 ))
  (labels ((cmd (fmt-str &rest args)
	     (mgl-gnuplot:command (apply #'format nil fmt-str args))))
    (mgl-gnuplot:with-session ()
      (cmd "reset")
      (cmd "set terminal wxt enhanced font 'Georgia,8' dashed")
      ;; (mgl-gnuplot:plot*
      ;;  (ba:plot-parameter-distribution (ba:get-parameter-results mcmc-result2 :no-bins 100) 'fp::om-c))
      ;; (mgl-gnuplot:plot*
      ;;  (ba:plot-parameter-distribution (ba:get-parameter-results nlopt-result :no-bins 100) 'fp::rho-m0))
      ;; (mgl-gnuplot:plot*
      ;;  (ba:plot-iteration-values mcmc-result :params-to-plot '(fp::om-c)))
      (mgl-gnuplot:plot* (ba:plot-result (ba:get-parameter-results mcmc-result :no-bins 100)))
      (cmd "unset output"))
    ))

(labels ((cmd (fmt-str &rest args)
	   (mgl-gnuplot:command (apply #'format nil fmt-str args))))
  (mgl-gnuplot:with-session ()
    (cmd "reset")
    (cmd "set terminal wxt enhanced font 'Georgia,8' dashed")
    (let+ (((&slots ba::input-model ba:model ba:data) *result*))
      (mgl-gnuplot:plot*
       (ba:plot-parameter-distribution
	(do-metrohastings *test-file* :max-tof 50 :no-iterations 100000)
				       'fp::om-c))) 
    (cmd "unset output")))
#+END_SRC

that was easy enough
*** integration of a single parameter
- doing this in [[file:./integration.lisp]]
- mathematically
  #+BEGIN_EXPORT latex 
  \begin{equation}
  \label{eq:posterior-parameter}
  p \left( x | X, I) \propto p( x|I\right) \int_{x_1}^{x_2}dx p(x|I)p(D|x, X, I)
  \end{equation}
  #+END_EXPORT
- first implementation in integrate-over
  - making use of existing likelihood/model
  - is changing the model, so this should be copied before given to
    integrate-over
  - needed to add integration functionality to gsl-cffi
  - need functionality to get prior for parameter
    + making use of the fact that the array of priors and the list of
      parameters should be in the same order
    + not taking advantage of the fact that priors could be constant
      and need not to be integrated over
    + the function just integrates over all the given parameters

- get-integration-fun-for-parameter:

  given a function G(M) of the model M given in MODEL , this function
  will return a function, denoted as F, that integrates over the
  parameter given by PARAMETER, denoted by x, as follows:

  \begin{equation}
  \label{eq:1}
  f \left( M \right) \rightarrow \int_{x_0}^{x_1} dx\ p\left( x | M, I \right) \cdot G(M)
  \end{equation}

- need to keep the array of priors to actually have them for straight
  integration
** DONE installing nlopt
* possible optimizations
** TODO seperate priors in constant/varying when integrating
\begin{equation}
\label{eq:2}
J\ddot{\phi} + k\dot{\phi} + D\phi = F(t)
\end{equation}
